{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Route Optimization (Reinforcement Learning with TensorFlow) ---\n",
        "import tensorflow as tf\n",
        "import gymnasium as gym\n",
        "import networkx as nx\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# 1. Define the Environment (Road Network)\n",
        "class DeliveryEnvironment(gym.Env):\n",
        "    def __init__(self, graph, start_node, end_node):\n",
        "        super(DeliveryEnvironment, self).__init__()\n",
        "        self.graph = graph  # NetworkX graph\n",
        "        self.start_node = start_node\n",
        "        self.end_node = end_node\n",
        "        self.current_node = start_node\n",
        "        self.path = [start_node]  # Store the path taken\n",
        "        self.action_space = gym.spaces.Discrete(len(list(graph.neighbors(start_node))))  # Number of neighbors\n",
        "        self.observation_space = gym.spaces.Tuple((\n",
        "            gym.spaces.Discrete(len(graph.nodes)),  # Current node\n",
        "            gym.spaces.Discrete(len(graph.nodes)),  # End node\n",
        "        ))\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        self.current_node = self.start_node\n",
        "        self.path = [self.start_node]\n",
        "        return self._get_obs(), {}\n",
        "\n",
        "    def _get_obs(self):\n",
        "        return (self.current_node, self.end_node)\n",
        "\n",
        "    def step(self, action):\n",
        "        next_node = list(self.graph.neighbors(self.current_node))[action]\n",
        "        self.path.append(next_node)\n",
        "        self.current_node = next_node\n",
        "\n",
        "        if self.current_node == self.end_node:\n",
        "            reward = -len(self.path)  # Negative path length (shorter is better)\n",
        "            done = True\n",
        "        else:\n",
        "            reward = -1  # Small penalty for each step\n",
        "            done = False\n",
        "\n",
        "        observation = self._get_obs()\n",
        "        info = {}\n",
        "\n",
        "        return observation, reward, done, False, info\n",
        "\n",
        "    def render(self):\n",
        "        print(f\"Current Node: {self.current_node}, Path: {self.path}\")\n",
        "\n",
        "# 2. Create a Sample Road Network (NetworkX)\n",
        "# In a real scenario, you would load this from a database or API\n",
        "graph = nx.Graph()\n",
        "graph.add_edges_from([(0, 1), (0, 2), (1, 3), (2, 3), (3, 4)])\n",
        "start_node = 0\n",
        "end_node = 4\n",
        "\n",
        "# 3. Build a Simple RL Model (TensorFlow) - Q-Network\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(16, activation='relu', input_shape=(2,)),  # Input: (current_node, end_node)\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='linear')  # Output: Q-values for each action (neighbor)\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "# 4. Training Loop\n",
        "env = DeliveryEnvironment(graph, start_node, end_node)\n",
        "episodes = 1000\n",
        "gamma = 0.9  # Discount factor\n",
        "epsilon = 0.1  # Exploration rate\n",
        "\n",
        "for episode in range(episodes):\n",
        "    state, _ = env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        # Epsilon-greedy action selection\n",
        "        if random.random() < epsilon:\n",
        "            action = env.action_space.sample()  # Explore\n",
        "        else:\n",
        "            state_tensor = tf.convert_to_tensor(np.array([state]))\n",
        "            q_values = model(state_tensor)\n",
        "            action = tf.argmax(q_values[0]).numpy()  # Exploit\n",
        "\n",
        "        next_state, reward, done, _, _ = env.step(action)\n",
        "\n",
        "        # Calculate target Q-value\n",
        "        next_state_tensor = tf.convert_to_tensor(np.array([next_state]))\n",
        "        next_q_values = model(next_state_tensor)\n",
        "        target_q_value = reward + gamma * tf.reduce_max(next_q_values)\n",
        "\n",
        "        # Calculate loss and update model\n",
        "        with tf.GradientTape() as tape:\n",
        "            state_tensor = tf.convert_to_tensor(np.array([state]))\n",
        "            q_values = model(state_tensor)\n",
        "            action_mask = tf.one_hot(action, depth=env.action_space.n)\n",
        "            predicted_q_value = tf.reduce_sum(q_values * action_mask, axis=1)\n",
        "            loss = loss_fn(target_q_value, predicted_q_value)\n",
        "\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        state = next_state\n",
        "    if (episode + 1) % 100 == 0:\n",
        "        print(f\"Episode {episode + 1}: Path: {env.path}, Reward: {reward}\")\n",
        "\n",
        "# --- 2. Delivery Time Prediction (Supervised Learning with XGBoost) ---\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# 1. Load and Prepare Data\n",
        "# Assuming you have a CSV file with historical delivery data\n",
        "# You can replace this with a dictionary if you're defining the data directly in the notebook\n",
        "data = pd.read_csv('delivery_data.csv')  # Replace with your data file\n",
        "# Feature Engineering\n",
        "data['pickup_time'] = pd.to_datetime(data['pickup_time'])\n",
        "data['dropoff_time'] = pd.to_datetime(data['dropoff_time'])\n",
        "data['duration_seconds'] = (data['dropoff_time'] - data['pickup_time']).dt.total_seconds()\n",
        "data['distance_km'] = data['distance_km'].astype(float)  # ensure distance is float\n",
        "data['hour'] = data['pickup_time'].dt.hour\n",
        "data['day_of_week'] = data['pickup_time'].dt.dayofweek\n",
        "data['month'] = data['pickup_time'].dt.month\n",
        "\n",
        "# Select Features and Target\n",
        "features = ['pickup_location_lat', 'pickup_location_lng', 'dropoff_location_lat', 'dropoff_location_lng', 'distance_km', 'hour', 'day_of_week', 'month']  # make sure 'distance_km' is included\n",
        "target = 'duration_seconds'\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# 2. Split Data into Training and Testing Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Train the XGBoost Model\n",
        "model = xgb.XGBRegressor(\n",
        "    objective='reg:squarederror',  # Regression objective\n",
        "    n_estimators=100,  # Number of boosting rounds\n",
        "    learning_rate=0.1,\n",
        "    max_depth=5,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Make Predictions and Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "\n",
        "\n",
        "# 5. Use the Model for Prediction\n",
        "def predict_delivery_time(pickup_location_lat, pickup_location_lng, dropoff_location_lat, dropoff_location_lng, distance_km, hour, day_of_week, month):\n",
        "    input_data = pd.DataFrame({\n",
        "        'pickup_location_lat': [pickup_location_lat],\n",
        "        'pickup_location_lng': [pickup_location_lng],\n",
        "        'dropoff_location_lat': [dropoff_location_lat],\n",
        "        'dropoff_location_lng': [dropoff_location_lng],\n",
        "        'distance_km': [distance_km],\n",
        "        'hour': [hour],\n",
        "        'day_of_week': [day_of_week],\n",
        "        'month': [month],\n",
        "    })\n",
        "    prediction = model.predict(input_data)[0]\n",
        "    return prediction\n",
        "\n",
        "\n",
        "# Example\n",
        "predicted_time = predict_delivery_time(-1.28325, 36.82184, -1.30271, 36.78205, 10.5, 14, 1, 5)\n",
        "print(f\"Predicted Delivery Time: {predicted_time:.2f} seconds\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "gGVVVjhmfZHf"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}